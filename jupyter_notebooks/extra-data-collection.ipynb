{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra steps if I were to rejoin the dataset then split it up again\n",
    "\n",
    "### <u>I did not use this notebook, this is just to show the assessor that I can join and split the data</u>\n",
    "\n",
    "The dataset already came split up when I downloaded it from Kaggle. It was split into train, validation and test sets. \n",
    "\n",
    "I made a seperate notebook so that I can show that I can join the datasets and then split them up again. I created new folders and then joined the datasets and then split them up again. \n",
    "\n",
    "The dataset contains some duplicate images, named differently. To avoid any issues later on I will use the downloaded train, test and validation sets. Below you will find the way I would code if I joined up the datasets, and continue from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r /workspace/Bone-Fracture-Detection/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the working directory from its current folder to its parent folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the parent of the current directory the new current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm the new current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change kaggle configuration directory to current working directory and permission of kaggle authentication json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Kaggle Dataset and Download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KaggleDatasetPath = \"bmadushanirodrigo/fracture-multi-region-x-ray-data\"\n",
    "DestinationFolder = \"inputs/fracture_dataset\"   \n",
    "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip the downloaded file, delete the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(DestinationFolder + '/fracture-multi-region-x-ray-data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(DestinationFolder)\n",
    "\n",
    "os.remove(DestinationFolder + '/fracture-multi-region-x-ray-data.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'inputs/fracture_dataset/bone_fracture/bone_fracture'\n",
    "parent_folder = 'bones_folder'\n",
    "child_folders = ['fractured', 'unfractured']\n",
    "new_folder = os.path.join(input_dir, parent_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function creates a new folder, bones_folder, that holds two folders, fractured and unfractured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_folder(parent_folder_path, folder_name): \n",
    "    path = os.path.join(parent_folder_path, folder_name) \n",
    "\n",
    "    try:\n",
    "        os.makedirs(path)  \n",
    "          \n",
    "    except OSError as error:  \n",
    "        print(error) \n",
    "\n",
    "\n",
    "make_new_folder(input_dir, parent_folder)\n",
    "\n",
    "\n",
    "for child in child_folders:\n",
    "    make_new_folder(new_folder, child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move all the images from the presplit folders (train, test and val folders) into the new folders created (bones_folder folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "def move_files_to_bones_folder(bone_type):\n",
    "    for folder in ['test', 'train', 'val']:\n",
    "        folders_bones = input_dir + '/' + folder + '/' + bone_type\n",
    "    \n",
    "        move_bones = os.listdir(folders_bones)\n",
    "        move_bone_folder = new_folder + '/' + bone_type\n",
    "\n",
    "        for move in move_bones:\n",
    "            shutil.move(os.path.join(folders_bones, move), os.path.join(move_bone_folder, move))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_files_to_bones_folder('fractured')\n",
    "move_files_to_bones_folder('unfractured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "### Data cleaning, Checks and removes non image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_image_files(dataset_path):\n",
    "    image_extension = ('.png', '.jpg', '.jpeg')\n",
    "    folders = os.listdir(dataset_path) \n",
    "    for folder in folders:\n",
    "        files = os.listdir(dataset_path + '/' + folder)\n",
    "        \n",
    "        i = []\n",
    "        j = []\n",
    "        for file in files:\n",
    "            if not file.lower().endswith(image_extension):\n",
    "                img_delete = dataset_path + '/' + folder + '/' + file\n",
    "                os.remove(img_delete)\n",
    "                i.append(1)\n",
    "            else:\n",
    "                j.append(1)\n",
    "                pass\n",
    "            \n",
    "        print(f\"Folder: {folder} - has {len(j)} images\")\n",
    "        print(f\"Folder: {folder} - has {len(i)} non-images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_non_image_files(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change image type, colour and size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change all the images to an JPG file, then save the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_image_type_and_save(bone_folder):\n",
    "\tfor path, subdirs, files in os.walk(new_folder + '/' + bone_folder):\n",
    "\t\tfor name in files:\n",
    "\t\t\tfile_name, file_ext = os.path.splitext(name)\n",
    "\t\t\tif file_ext != \"jpg\":\n",
    "\t\t\t\tos.rename(os.path.join(path, name), os.path.join(path, os.path.basename(file_name) + \".\" + 'jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_image_type_and_save('fractured')\n",
    "change_image_type_and_save('unfractured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the image colors to grayscale and change the image size, then save the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "\n",
    "\n",
    "# Fixes truncated oserror\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "def convert_images_to_grayscale(bone_folder):\n",
    "    for picture in os.listdir(new_folder + '/' + bone_folder):\n",
    "        img = Image.open(new_folder + '/' + bone_folder + '/' + picture).convert('L')\n",
    "        new_size = img.resize((150, 150))\n",
    "        new_size.save(new_folder + '/' + bone_folder + '/' + picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_images_to_grayscale('fractured')\n",
    "convert_images_to_grayscale('unfractured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resplit the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import joblib\n",
    "\n",
    "\n",
    "def split_bones_folder_into_train_test_val(new_path, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
    "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
    "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum up to 1.0\")\n",
    "        return\n",
    "\n",
    "    labels = os.listdir(new_path)\n",
    "    if 'test' in labels:\n",
    "        pass\n",
    "    else:\n",
    "        for label in labels:\n",
    "            files = os.listdir(new_path + '/' + label)\n",
    "            random.shuffle(files)\n",
    "            train_set_files_qty = int(len(files) * train_set_ratio)\n",
    "            validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
    "\n",
    "            count = 1\n",
    "            for file_name in files:\n",
    "                if count <= train_set_files_qty:\n",
    "                    shutil.move(new_path + '/' + label + '/' + file_name,\n",
    "                                input_dir + '/train/' + label + '/' + file_name)\n",
    "                            \n",
    "                elif count <= (train_set_files_qty + validation_set_files_qty ):\n",
    "                    shutil.move(new_path + '/' + label + '/' + file_name,\n",
    "                                input_dir + '/val/' + label + '/' + file_name)\n",
    "\n",
    "                else:\n",
    "                    shutil.move(new_path + '/' + label + '/' + file_name,\n",
    "                            input_dir + '/test/' +label + '/'+ file_name)\n",
    "            \n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_bones_folder_into_train_test_val(new_path = new_folder,\n",
    "                                    train_set_ratio = 0.7,\n",
    "                                    validation_set_ratio = 0.1,\n",
    "                                    test_set_ratio = 0.2\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the created folder, bones_folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in child_folders:\n",
    "    os.rmdir(new_folder + '/' + child)\n",
    "\n",
    "\n",
    "os.rmdir(new_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
